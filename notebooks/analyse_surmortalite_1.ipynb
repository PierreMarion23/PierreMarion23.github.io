{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Estimer la surmortalité causée par l'épidémie de Covid-19 en France (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combien de personnes sont décèdées des suites du coronavirus depuis le début de l'épidémie ? Au 13 avril, le chiffre officiel est de 9 588 décès (en milieu hospitalier et en EHPAD), mais chacun se doute que le \"vrai\" chiffre est largement supérieur. Mais de combien ? Nous allons voir qu'il y a eu environ 15 400 décès additionnels causés par l'épidémie jusqu'au 13 avril, soit environ 1.6 fois le chiffre officiel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Téléchargements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour télécharger ce notebook : https://pierremarion23.github.io/notebooks/analyse_surmortalite_1.ipynb\n",
    "\n",
    "Avant de l'exécuter, il faut télécharger et exécuter le noteboook de préparation des données : https://pierremarion23.github.io/notebooks/prep_donnees_covid.ipynb\n",
    "\n",
    "Notebook suivant : https://pierremarion23.github.io/notebooks/analyse_surmortalite_2.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Source de données : INSEE (voir fichier de préparation des données pour les détails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Afin d'éclairer la mortalité due à l'épidémie du coronavirus, l'INSEE a récemment publié des données de mortalité des premiers mois des années 2018 à 2020, agrégées selon différentes dimensions (âge, sexe, département, jour de décès) [1]. Ces données ont été reprises dans les médias, voir par exemple [un article du Monde](https://www.lemonde.fr/les-decodeurs/article/2020/04/10/coronavirus-la-surmortalite-en-france-par-age-sexe-et-departement_6036275_4355770.html), afin d'estimer la surmortalité en 2020 causée par l'épidémie. Néanmoins, une comparaison directe du nombre de décès en mars 2020 à celui en 2018 et 2019 comprend des biais importants, et ce pour deux raisons principales :\n",
    "+ l'augmentation de la population, en particulier âgée, entraîne mécaniquement une augmentation des décès chaque année, ce qui entraîne une sur-estimation de la surmortalité due au coronavirus.\n",
    "+ le mois de mars est marqué par la fin de l'épidémie de grippe chaque année. Or l'épidémie de grippe de 2019-2020 a été particulièrement clémente, contrairement à celle de 2017-2018 qui a été particulièrement longue et a entraîné plusieurs milliers de décès en mars 2018, ce qui entraîne une sous-estimation de la surmortalité due au coronavirus.\n",
    "\n",
    "Nous allons essayons de corriger ces deux biais. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention, changer cette valeur avant d'exécuter le notebook (voir nb de préparation des données)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_treated_data = 'treated_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import datetime\n",
    "import sklearn\n",
    "import bqplot\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ipywidgets as ipw\n",
    "\n",
    "from bqplot import pyplot as plt\n",
    "from bqplot import DateScale, LinearScale, Scatter, Lines, Axis, Figure\n",
    "from scipy import stats as scs\n",
    "from numpy import random as npr\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from bqplot.traits import convert_to_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dates de début et de fin de la période d'étude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_debut = datetime.datetime(2020, 2, 15)\n",
    "date_fin = datetime.datetime(2020, 4, 13)\n",
    "period = [date_debut + datetime.timedelta(days=k) for k in range((date_fin-date_debut).days+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre source de donnée principale est une table recensant tous les décès depuis 1998 jusqu'au 6 avril 2020, avec des informations sur chaque décès (sexe de la personne, âge, date du décès, département de décès)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(folder_treated_data, 'deces9820.pkl')\n",
    "deces9820 = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deces9820.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total2020 = ((deces9820['deces_date'] >= date_debut) & (deces9820['deces_date'] <= date_fin)).sum()\n",
    "total2019 = ((deces9820['deces_date'] >= date_debut-datetime.timedelta(days=366)) & (deces9820['deces_date'] <= date_fin-datetime.timedelta(weeks=52))).sum()\n",
    "total2018 = ((deces9820['deces_date'] >= date_debut-datetime.timedelta(days=365+366)) & (deces9820['deces_date'] <= date_fin-datetime.timedelta(weeks=2*52))).sum()\n",
    "print(\"Deces du {} jusqu'au {} : {}\".format(date_debut, date_fin, total2020))\n",
    "print(\"Deces du {} jusqu'au {} : {}\".format(date_debut-datetime.timedelta(days=366), date_fin-datetime.timedelta(days=366), total2019))\n",
    "print(\"Deces du {} jusqu'au {} : {}\".format(date_debut-datetime.timedelta(days=365+366), date_fin-datetime.timedelta(days=366+365), total2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total2020 - 0.5*(total2019 + total2018))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "En analysant directement les données de l'INSEE, on conclut donc à une augmentation des décès de 5 884 sur la période par rapport aux deux années précédentes. Or on sait qu'au jour du 13 avril, 9 588 personnes étaient décèdées du coronavirus en milieu hospitalier et EHPAD ([chiffres officiels de Santé Publique France](https://www.francetvinfo.fr/sante/maladie/coronavirus/infographies-covid-19-morts-hospitalisations-age-malades-l-evolution-de-l-epidemie-en-france-et-dans-le-monde-en-cartes-et-graphiques.html)), donc on a largement sous-estimé l'impact de l'épidémie par cette méthode naïve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Redressement de l'augmentation de la population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Pour tenir compte de l'augmentation de la population, on va diviser le nombre de décès quotidiens par son espérance, donnée par des tables de mortalité et de population mises à jour chaque année. Commençons par préparer ces tables grâce aux données démographiques de l'INSEE. On agrège les décès par âge, sexe, et année de décès."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deces_sexe_annee_age = pd.pivot_table(deces9820,values='depdeces', index=['sexe', 'annee'], columns=['age'], aggfunc='count', fill_value=0)\n",
    "deces_sexe_annee_age[100] = deces_sexe_annee_age.loc[:,[x for x in deces_sexe_annee_age.columns if x >= 100]].sum(axis=1)\n",
    "deces_sexe_annee_age.drop(columns=[x for x in deces_sexe_annee_age.columns if x > 100], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deces_sexe_annee_age.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On introduit une deuxième source de données : la popluation par âge et par sexe de 1991 à 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(folder_treated_data, 'population_age_sexe_9820.pkl')\n",
    "population_sexe_annee_age = pd.read_pickle(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_sexe_annee_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(20, 101), deces_sexe_annee_age.loc[(1, 2014)], labels=['Décès'])\n",
    "plt.plot(np.arange(20, 101), population_sexe_annee_age.loc[(1, 2014)], colors=['green'], labels=['Population'])\n",
    "plt.title(\"Population et nombre de décès dans l'année par âge au 1er janvier chez les hommes en 2014\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En divisant le nombre de morts par la population, on obtient des probabilités de décès par année, sexe, et âge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourc_mortalite = deces_sexe_annee_age.loc[(slice(None), slice(1998, 2019)), :] / population_sexe_annee_age.loc[(slice(1, 2), slice(1998, 2019)), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourc_mortalite.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On fait une moyenne glissante sur 5 ans, pour lisser les fluctuations aléatoires, ce qui nous donne des tables de décès par année, sexe, et âge, de 2000 à 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pourc_mortalite_np = pourc_mortalite.to_numpy().reshape(2, 22, 81)\n",
    "pourc_mortalite_np = np.hstack((np.zeros((2, 1, 81)), pourc_mortalite_np))\n",
    "table_mortalite_av = np.cumsum(pourc_mortalite_np, axis=1)\n",
    "# moyenne glissante entre 2000 et 2017\n",
    "table_mortalite_av = ((table_mortalite_av[:,5:,:]-table_mortalite_av[:,:-5,:]) / 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projection des tables de mortalité sur 2018 à 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour obtenir les tables de décès en 2018 et 2020, on projette de manière un peu brutale : on calcule la variation moyenne de probabilité de décès pour chaque âge et chaque sexe, entre 2014 et 2017, puis on suppose que cette variation continue de la même manière entre 2017 et 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gain annuel moyen entre 2014 et 2017\n",
    "gain_annuel = np.mean(np.diff(table_mortalite_av[:, -4:, :], axis=1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projection sur 2018-2020\n",
    "n_annee_proj = 3\n",
    "table_mortalite_proj = np.zeros((2, n_annee_proj, 81))\n",
    "for k in range(n_annee_proj):\n",
    "    table_mortalite_proj[:, k, :] = table_mortalite_av[:, -1, :] + (k+1) * gain_annuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_mortalite_np = np.hstack((table_mortalite_av, table_mortalite_proj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_mortalite = pd.DataFrame(table_mortalite_np.reshape(42,81))\n",
    "table_mortalite.columns = pourc_mortalite.columns\n",
    "table_mortalite.index = pd.MultiIndex.from_arrays([[1]*21 + [2]*21, np.hstack((np.arange(2000, 2021), np.arange(2000, 2021)))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient finalement une table de mortalité jusqu'en 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_mortalite.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut visualiser ces tables de mortalité en traçant la fonction de survie (c'est-à-dire la probabilité d'atteindre un âge donné), en fonction du sexe et de l'année. On visualise le gain d'espérance de vie au cours des années, ainsi que la différence entre hommes et femmes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fct_survie_H = np.cumprod(1-table_mortalite_np[0], axis=1)\n",
    "fct_survie_F = np.cumprod(1-table_mortalite_np[1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for k in range(0, 24, 4):\n",
    "    plt.plot(np.arange(20, 101), fct_survie_H[k], colors=[bqplot.CATEGORY10[k//4]], labels=['20{:02}'.format(k)], display_legend=True)\n",
    "    plt.plot(np.arange(20, 101), fct_survie_F[k], colors=[bqplot.CATEGORY10[k//4]])\n",
    "plt.xlabel('Âge')\n",
    "plt.ylabel('Valeur de la fonction de survie')\n",
    "plt.title('Evolution de la fonction de survie des adultes sur 20 ans')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir des tables de mortalité et des tables de population, on calcule facilement l'espérance du nombre de décès annuel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "# espérance du nombre de morts annuels entre 2000 et 2020\n",
    "morts_par_an_esp = np.einsum('ijk,ijk->j', table_mortalite_np, population_sexe_annee_age.loc[(slice(1, 2), slice(2000, 2020)), :].to_numpy().reshape(2, 21, 81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(2000, 2021), morts_par_an_esp)\n",
    "plt.title('Espérance du nombre de décès annuels dans la population adulte')\n",
    "plt.ylim(0, 640000)\n",
    "plt.show(display_toolbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "On constate que l'espérance du nombre de décès annuels, qui stagne autour de 550 000 entre 2000 et 2012 augmente rapidement dans la décennie 2010 pour atteindre 650 000 en 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Traçons maintenant le nombre de décès journaliers en mars, pour les années entre 2000 et 2020, divisés par 1/365ème de l'espérance des décès l'année correspondante, afin de tenir compte de l'augmentation de la population. Grâce à cette normalisation, on s'attend donc à ce que ces courbent présentent des fluctuations aléatoires autour de 1, sauf la courbe de 2020 qui devrait exploser dans la deuxième moitié de mars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decalage = (date_debut - datetime.datetime(2020, 1, 1)).days\n",
    "duree_periode = (date_fin-date_debut).days + 1\n",
    "n_training = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deces9820['delta_debut'] = deces9820['jour_annee'] - decalage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deces_par_jour = pd.pivot_table(deces9820[(deces9820['delta_debut'] >= 0) & (deces9820['delta_debut'] <= duree_periode-1) & (deces9820['annee'] >= 2000)], values='depdeces', index=['annee'], columns=['delta_debut'], aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deces_par_jour.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "deces_par_jour_np = deces_par_jour.to_numpy()\n",
    "# Entre 2000 et 2019\n",
    "y_0019 = 365 * deces_par_jour_np[:-1] / np.repeat(morts_par_an_esp[:-1], repeats=duree_periode).reshape(n_training, duree_periode)\n",
    "y_20 = 365 * deces_par_jour_np[-1] / np.repeat(morts_par_an_esp[-1], repeats=duree_periode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = pd.to_datetime(period)\n",
    "for k in range(n_training):\n",
    "    plt.plot(x, y_0019[k], colors=[bqplot.CATEGORY10[k%10]])\n",
    "plt.plot(x, y_20, colors=['red'], labels=['2020'], display_legend=True, marker='circle')\n",
    "plt.xlabel(\"Période d'étude\")\n",
    "plt.ylabel('Ratio du nombre de décès')\n",
    "plt.title(\"Nombre de décès journaliers rapporté à 1/365e de l'espérance des décès annuels, entre 2000 et 2020\")\n",
    "plt.ylim(min=0.7, max=1.5)\n",
    "plt.show(display_toolbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "On constate que les courbes sont tendanciellement au dessus de 1, en particulier pendant la première quinzaine de mars. Ceci est dû à la répartition inégale des décès dans l'année : il y a plus de décès journaliers en mars qu'en moyenne sur l'année, en particulier à cause de l'épidémie de grippe. Les quelques courbes présentant des ratios supérieurs à 1.2 correspondent à des épidémies de grippe très virulentes en mars, sauf 2020, où l'explosion en deuxième moitié de mois est due au coronavirus.\n",
    "\n",
    "On remarque aussi que mars 2020 avait commencé avec une mortalité très faible (même historiquement faible autour du 7-8 mars). Cela est sans doute dû à une combinaison de facteurs : grippe clémente en 2020, diminution des morts accidentelles grâce au confinement, problèmes de remontée de données les 7 et 8 (qui sont un week-end). \n",
    "\n",
    "Malgré cela, on fait l'hypothèse en première approximation que le nombre de décès pendant la première quinzaine de mars n'a quasiment pas été influencé par l'épidémie. Pour connaître le nombre de morts dus au coronavirus, on souhaiterait donc \"prolonger\" la courbe de début mars 2020 pour obtenir une distribution de courbes de mortalité dans la seconde moitié du mois de mars, en l'absence de coronavirus. Ensuite il suffira de calculer la différence entre la courbe réalisée et la moyenne de cette distribution, pour estimer le nombre de morts excédentaires.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Régressions linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Pour cela, on propose un modèle de [régression linéaire bayésienne](https://en.wikipedia.org/wiki/Bayesian_linear_regression). On suppose donc que les décès au $i$-ème jour de mars l'année $t$ s'écrivent :\n",
    "\n",
    "$$y_{t,i} = a_t  i + b_t \\exp(-(i-15)^2/128) + c_t + \\epsilon_{t,i}$$\n",
    "\n",
    "où les $(\\epsilon_{t,i})_i$ sont i.i.d. de loi normale de variance $\\sigma_t^2$, les $(a_t, b_t, c_t)$ sont i.i.d. et suivent une loi normale (à 3 dimensions) également de variance $\\sigma_t^2$, et enfin les $\\sigma_t^2$ sont i.i.d. de loi inverse-gamma. Le rôle du coefficient $b_t$ est de modéliser une grippe tardive en mars (courbe en cloche centrée autour du 1er mars).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Pour justifier cette hypothèse de normalité sur $(a_t, b_t)$, on peut estimer les coefficients $a_t$ et $b_t$ pour $t$ entre 2000 et 2019. On commence par tracer chaque régression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.arange(duree_periode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = scs.norm.pdf(np.arange(duree_periode), loc=20, scale=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([x1, x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "x_sc = DateScale()\n",
    "y_sc = LinearScale()\n",
    "x = pd.to_datetime(period)\n",
    "\n",
    "ax_x = Axis(label='X', scale=x_sc, grid_lines='solid', tick_values = pd.to_datetime([date_debut + datetime.timedelta(days=k) for k in range(0, (date_fin-date_debut).days+1, 15)]))\n",
    "ax_y = Axis(label='Y', scale=y_sc, orientation='vertical', grid_lines='solid', max=1.4)\n",
    "scatters = []\n",
    "lines = []\n",
    "coefs = []\n",
    "intercepts = []\n",
    "\n",
    "for k in range(n_training):\n",
    "    # Instantiate a Linear regression model\n",
    "    reg = LinearRegression()\n",
    "\n",
    "    # Fit to data\n",
    "    reg.fit(X.T, y_0019[k])    \n",
    "    y_pred = reg.predict(X.T)\n",
    "    scatters.append(Scatter(x=x, y=y_0019[k], scales={'x': x_sc, 'y': y_sc}, default_size=32))\n",
    "    lines.append(Lines(x=x, y=y_pred, scales={'x': x_sc, 'y': y_sc}))\n",
    "    coefs.append(reg.coef_)\n",
    "    intercepts.append(reg.intercept_)\n",
    "\n",
    "coefs = np.array(coefs)\n",
    "figy=[]\n",
    "for i in range(5):\n",
    "    figx=[]\n",
    "    for j in range(4):\n",
    "        figx.append(Figure(axes=[ax_x, ax_y], marks=[scatters[i*4+j], lines[i*4+j]], title=str(2000 + i*4+j), fig_margin = dict(top=30, bottom=20, left=20, right=20), layout={'width':\"240px\", 'height':'200px'}))\n",
    "    figy.append(ipw.HBox(figx)) \n",
    "display(ipw.VBox(figy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Ensuite on trace le scatter plot des coefficients $a_t$, $b_t$ et $c_t$ de la régression linéaire, afin de vérifier que leur distribution est approximativement gaussienne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "fig = []\n",
    "scatters = [Scatter(x=coefs[:,0], y=coefs[:,1], scales={'x': LinearScale(), 'y': LinearScale()}), \n",
    "            Scatter(x=coefs[:,1], y=intercepts, scales={'x': LinearScale(), 'y': LinearScale()}),\n",
    "            Scatter(x=coefs[:,0], y=intercepts, scales={'x': LinearScale(), 'y': LinearScale()})]\n",
    "for scatter, title in zip(scatters, ['a versus b', 'b versus c', 'a versus c']):\n",
    "    ax_x = Axis(scale=x_sc, grid_lines='solid')\n",
    "    ax_y = Axis(scale=y_sc, orientation='vertical', grid_lines='solid')\n",
    "    fig.append(Figure(axes=[ax_x, ax_y], marks=[scatter], title=title, fig_margin = dict(top=30, bottom=10, left=20, right=20), layout={'width':\"400px\", 'height':'400px'}))\n",
    "display(ipw.HBox(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Calcul des paramètres de la loi a priori et a posteriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Pour les paramètres a priori, on utilise des estimateurs basés sur la moyenne des années 2000 à 2019, en enlevant les années de grippe virulente (ratio de décès le 1er mars supérieur à 1.15). On met à jour les paramètres a posteriori dans la fonction `compute_post_param` en utilisant les `n` premiers jours de mars 2020. Les formules sont basées sur celles données dans [l'article Wikipedia sur la régression linéaire bayésienne](https://en.wikipedia.org/wiki/Bayesian_linear_regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = -1\n",
    "x0 = np.ones((1, duree_periode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "f = 30\n",
    "y = np.mean(y_0019, axis=0)\n",
    "T = y_0019.shape[0]\n",
    "X = np.vstack((x0, x1, x2)).T\n",
    "lambd_0 = np.matmul(X.T, X) / f\n",
    "mu_0 = np.matmul(np.matmul(np.linalg.inv(lambd_0), X.T), y) / f\n",
    "a_0 = duree_periode/(2*f)\n",
    "b_0 = 0.5 * (np.sum(y*y) - f * np.sum(mu_0 * (lambd_0 @ mu_0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "lambd_post = {}\n",
    "mu_post = {}\n",
    "a_post = {}\n",
    "b_post = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def compute_post_param(n_start):\n",
    "    X_2020 = np.vstack((x0, x1, x2))[:,:n_start].T\n",
    "    lambd_post[n_start] = lambd_0 + np.matmul(X_2020.T, X_2020)\n",
    "    mu_post[n_start] = np.matmul(np.linalg.inv(lambd_post[n_start]), lambd_0 @ mu_0 + X_2020.T @ y_20[:n_start])\n",
    "    a_post[n_start] = a_0 +n_start/2\n",
    "    b_post[n_start] = b_0 + 0.5 * (np.sum(y_20[:n_start]*y_20[:n_start]) + np.sum(mu_0 * (lambd_0 @ mu_0)) - np.sum(mu_post[n_start] * (lambd_post[n_start] @ mu_post[n_start])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Simulations de la loi a posteriori "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "def sample_post(N, n_start):\n",
    "    y_sims = np.zeros((N, duree_periode))\n",
    "\n",
    "    for k in range(N):\n",
    "        var = scs.invgamma.rvs(a_post[n_start], size=1) * b_post[n_start]\n",
    "        beta = npr.multivariate_normal(mu_post[n_start], var * np.linalg.inv(lambd_post[n_start]), size=1)\n",
    "        y_sims[k] = npr.multivariate_normal(np.dot(X, beta.T).flatten(), var * np.identity(duree_periode))\n",
    "        y_sims[k,:n_start] = y_20[:n_start]\n",
    "    return y_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_starts = [14, 20, 29]  # on fait la simulation pour différents jours de départ, ici le 14ème, 20ème, 28ème\n",
    "N = 10**3\n",
    "y_sims = {}\n",
    "moys  = {}\n",
    "env_infs = {}\n",
    "env_sups = {}\n",
    "for n_start in n_starts:\n",
    "    compute_post_param(n_start)\n",
    "    y_sims[n_start] = sample_post(N, n_start)\n",
    "    moys[n_start] = np.mean(y_sims[n_start], axis=0)\n",
    "    env_infs[n_start] = np.sort(y_sims[n_start], axis=0)[N//10]\n",
    "    env_sups[n_start] = np.sort(y_sims[n_start], axis=0)[N-N//10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "On peut maintenant tracer l'intervalle de confiance (à 90%) de l'évolution à partir du 15 mars du ratio de décès journalier. On constate que 2018 est entièrement en dehors de l'IC (à cause de la grippe), tandis que 2020 sort de l'IC à partir du 16 mars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(legend_location='bottom-left')\n",
    "x = pd.to_datetime(period)\n",
    "for k in range(len(y_0019[:-2])):\n",
    "    plt.plot(x, y_0019[k], colors=['gray'], opacities=[0.2])\n",
    "plt.plot(x, y_0019[-2], colors=['blue'], labels=['2018'], display_legend=True)\n",
    "plt.plot(x, y_0019[-1], colors=['violet'], labels=['2019'], display_legend=True)\n",
    "plt.plot(x, y_20, colors=['red'], labels=['2020'], display_legend=True)\n",
    "#plt.plot(x, pred, colors=['green'], labels=['2020 non bay'], display_legend=True)\n",
    "for n_start in [29]:\n",
    "    plt.plot(x[n_start-1:], env_infs[n_start][n_start-1:], colors=['black'], labels=['2020 sans covid (IC)'], line_style='dashed', display_legend=True)\n",
    "    plt.plot(x[n_start-1:], env_sups[n_start][n_start-1:], colors=['black'], line_style='dashed')\n",
    "    plt.plot(x[n_start-1:], moys[n_start][n_start-1:], colors=['black'], line_style='dashed')\n",
    "plt.xlabel(\"Période d'étude\")\n",
    "plt.ylabel('Ratio de décès journalier')\n",
    "plt.title(\"Evolution du ration de décès : 2020 sans covid\")\n",
    "plt.ylim(min=0.7, max=1.5)\n",
    "plt.show(display_toolbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "On finit en calculant le nombre de décès excédentaires : on constate qu'en espérance, avec notre modèle, il y a eu 15 400 décès supplémentaires pendant la période, soit 1.6 fois le nombre de décès constatés en milieu hospitalier et Ehpad au 13 avril (9 558). En mars, il y a eu 6 800 décès supplémentaires pendant la période, soit 1.8 fois le nombre de décès constatés en milieu hospitalier au 31 mars (3 523)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_start = 29\n",
    "moy_post = np.cumsum(moys[n_start])\n",
    "sup_post = np.sort(np.cumsum(y_sims[n_start], axis=1), axis=0)[N-N//20]\n",
    "inf_post = np.sort(np.cumsum(y_sims[n_start], axis=1), axis=0)[N//20]\n",
    "deces_realises = np.cumsum(y_20) \n",
    "deces_excedentaires = (pd.DataFrame([(deces_realises - moy_post), (deces_realises - sup_post), (deces_realises - inf_post)]) * morts_par_an_esp[-1] / 365).astype('int64').T\n",
    "deces_excedentaires.index = period\n",
    "deces_excedentaires = deces_excedentaires.loc[deces_excedentaires.index >= date_debut + datetime.timedelta(days=n_start)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(folder_treated_data, 'deces_hop_ehpad.pkl')\n",
    "deces_rapportes = pd.read_pickle(path)\n",
    "deces_rapportes = deces_rapportes.loc[deces_excedentaires.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(legend_location='top-left')\n",
    "plt.plot(deces_excedentaires.index, deces_rapportes['dc off'], colors=['green'], labels=['Valeurs rapportées'], display_legend=True)\n",
    "plt.plot(deces_excedentaires.index, deces_excedentaires[0], colors=['black'], labels=['Valeurs estimées (moy)'], display_legend=True)\n",
    "plt.plot(deces_excedentaires.index, deces_excedentaires[1], colors=['black'], line_style='dashed', labels=['Valeurs estimées (IC)'], display_legend=True)\n",
    "plt.plot(deces_excedentaires.index, deces_excedentaires[2], colors=['black'], line_style='dashed')\n",
    "plt.title(\"Nombre de décès excédentaires dus à l'épidémie\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque 1 : la taille de cet intervalle de confiance semble importante. On peut la comparer à la variabilité usuelle du nombre de décès. Pour cela, on trace les ratios de décès historiques cumulés sur la période considérée pour 2000-2019, auquel on superpose notre intervalle de confiance pour 2020. On voit que sa taille est cohérente par rapport à la variabilité historique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historic = np.sum(y_0019, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(legend_location='bottom-left')\n",
    "plt.scatter(np.arange(2000, 2020), historic, labels=['historique'])\n",
    "plt.hline(moy_post[-1], stroke_width=2, colors=['orangered'], labels=['moyenne 2020'], display_legend=True)\n",
    "plt.hline(sup_post[-1], stroke_width=2, colors=['orangered'], line_style='dashed', labels=['IC 2020'], display_legend=True)\n",
    "plt.hline(inf_post[-1], stroke_width=2, colors=['orangered'], line_style='dashed')\n",
    "plt.ylim(min=49, max=69)\n",
    "plt.title(\"Ratio de décès cumulés sur la période d'étude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Remarque 2 : le jour du début de la divergence entre \"2020 avec covid\" et \"2020 sans covid\" est choisie de manière arbitraire, car elle semble correspondre au début de l'augmentation significative de la mortalité. Si on choisit des dates antérieures, on obtient des résultats similaires (voir plot ci-dessous), avec des intervalles de confiance plus larges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "x = pd.to_datetime(period)\n",
    "plt.plot(x, y_20, colors=['red'], labels=['Courbe réelle'])\n",
    "for n_start in n_starts:\n",
    "    plt.plot(x[n_start-1:], env_infs[n_start][n_start-1:], colors=['gray'], labels=['Enveloppe inférieure'], line_style='dashed')\n",
    "    plt.plot(x[n_start-1:], moys[n_start][n_start-1:], colors=['black'])\n",
    "    plt.plot(x[n_start-1:], env_sups[n_start][n_start-1:], colors=['gray'], labels=['Enveloppe supérieure'], line_style='dashed')\n",
    "plt.xlabel('Jour depuis le début de la période')\n",
    "plt.ylabel('Ratio de décès')\n",
    "plt.title('Intervalles de confiance partant de trois dates pendant la période')\n",
    "plt.ylim(min=0.7, max=1.5)\n",
    "plt.show(display_toolbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Pistes d'amélioration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "+ stratifier par âge et par département : voir notebook suivant !\n",
    "+ estimer la réduction de mortalité due à la diminution de l'activité économique (morts de la route, morts professionnels), et la prendre en compte dans le modèle\n",
    "+ modéliser la grippe virulente de manière bayésienne (modèles mixtes) plutôt que d'exclure brutalement ces années des données\n",
    "+ utiliser des processus gaussiens plutôt que des régressions linéaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Pour l'illustration, on fit des processus gaussiens sur les données de 2000-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {},
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from bqplot import LinearScale, Scatter, Lines, Axis, Figure\n",
    "\n",
    "x_sc = DateScale()\n",
    "y_sc = LinearScale()\n",
    "\n",
    "ax_x = Axis(label='X', scale=x_sc, grid_lines='solid', tick_values = pd.to_datetime([date_debut + datetime.timedelta(days=k) for k in range(0, (date_fin-date_debut).days+1, 15)]))\n",
    "ax_y = Axis(label='Y', scale=y_sc, orientation='vertical', grid_lines='solid')\n",
    "scatters = []\n",
    "lines = []\n",
    "\n",
    "for k in range(20):\n",
    "    # Instantiate a Gaussian Process model\n",
    "    kernel = RBF(80, (4e1, 1e2))\n",
    "    gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9, alpha=8*10**-4)\n",
    "\n",
    "    # Fit to data using Maximum Likelihood Estimation of the parameters\n",
    "    x = np.array(range(duree_periode)).reshape(-1, 1)\n",
    "    gp.fit(x, y_0019[k])    \n",
    "    y_pred = gp.predict(x)\n",
    "    scatters.append(Scatter(x=pd.to_datetime(period), y=y_0019[k], scales={'x': x_sc, 'y': y_sc}, default_size=32))\n",
    "    lines.append(Lines(x=pd.to_datetime(period), y=y_pred, scales={'x': x_sc, 'y': y_sc}))\n",
    "    \n",
    "figy=[]\n",
    "for i in range(5):\n",
    "    figx=[]\n",
    "    for j in range(4):\n",
    "        figx.append(Figure(axes=[ax_x, ax_y], marks=[scatters[i*4+j], lines[i*4+j]], title=str(2000 + i*4+j), fig_margin = dict(top=30, bottom=20, left=20, right=20), layout={'width':\"240px\",'height':'200px'}))\n",
    "    figy.append(ipw.HBox(figx)) \n",
    "display(ipw.VBox(figy, align_content = 'stretch'))"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
